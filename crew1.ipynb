{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e617ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Core imports and configuration\n",
    "import os\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Core libraries\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import pipeline\n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import Mail\n",
    "from supabase import create_client, Client\n",
    "import google.generativeai as genai\n",
    "\n",
    "# CrewAI imports\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Market Coverage\n",
    "TICKERS = [\n",
    "    \"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"META\", \"GOOGL\", \"GOOG\", \"TSLA\", \"AVGO\", \"TSM\",\n",
    "    \"COST\", \"ADBE\", \"PEP\", \"CSCO\", \"ACN\", \"TMUS\", \"CMCSA\", \"AMD\", \"INTC\", \"INTU\",\n",
    "    \"AMGN\", \"REGN\", \"ADP\", \"QCOM\", \"VRTX\", \"AMAT\", \"ISRG\", \"MU\", \"ATVI\", \"MDLZ\",\n",
    "    \"PYPL\", \"ADSK\", \"MELI\", \"KLAC\", \"SNPS\", \"CDNS\", \"ASML\", \"CHTR\", \"MNST\", \"LRCX\",\n",
    "    \"ORLY\", \"KDP\", \"DXCM\", \"MAR\", \"IDXX\", \"CTAS\", \"ROST\", \"WDAY\", \"PCAR\", \"AZN\",\n",
    "    \"CPRT\", \"XEL\", \"DLTR\", \"FAST\", \"VRSK\", \"ANSS\", \"SGEN\", \"BIIB\", \"ALGN\", \"SIRI\",\n",
    "    \"EBAY\", \"EXC\", \"NTES\", \"JD\", \"BIDU\", \"SWKS\", \"INCY\", \"WBA\", \"ULTA\", \"TTWO\",\n",
    "    \"VRSN\", \"LULU\", \"MTCH\", \"ZM\", \"DOCU\", \"OKTA\", \"DDOG\", \"CRWD\", \"NET\", \"FTNT\",\n",
    "    \"ZS\", \"PANW\", \"TEAM\", \"PLTR\", \"DBX\", \"AFRM\", \"COIN\", \"HOOD\", \"DASH\", \"RIVN\",\n",
    "    \"LCID\", \"PTON\", \"ABNB\", \"UBER\", \"LYFT\", \"SNOW\", \"DDOG\", \"MDB\", \"TWLO\", \"SPLK\",\n",
    "    \"BRK.B\", \"JPM\", \"V\", \"MA\", \"BAC\", \"WFC\", \"GS\", \"AXP\", \"MS\", \"BLK\", \"C\",\n",
    "    \"XOM\", \"CVX\", \"LLY\", \"JNJ\", \"UNH\", \"ABBV\", \"MRK\", \"ABT\", \"PFE\", \"MDT\",\n",
    "    \"WMT\", \"PG\", \"KO\", \"HD\", \"MCD\", \"PEP\", \"TJX\", \"NKE\", \"SBUX\", \"MDLZ\", \"CL\",\n",
    "    \"GE\", \"UNP\", \"CAT\", \"HON\", \"RTX\", \"LMT\", \"UPS\", \"NOC\", \"BA\", \"CRM\"\n",
    "]\n",
    "\n",
    "# Environment variables (set these in your environment)\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "SENDGRID_API_KEY = os.getenv(\"SENDGRID_API_KEY\")\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Initialize services\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL else None\n",
    "genai.configure(api_key=GEMINI_API_KEY) if GEMINI_API_KEY else None\n",
    "\n",
    "@dataclass\n",
    "class MarketEvent:\n",
    "    timestamp: datetime\n",
    "    event_type: str\n",
    "    description: str\n",
    "    affected_tickers: List[str]\n",
    "    severity_score: float\n",
    "    source_url: str\n",
    "\n",
    "@dataclass\n",
    "class RiskAssessment:\n",
    "    event: MarketEvent\n",
    "    impact_analysis: str\n",
    "    probability_score: float\n",
    "    time_horizon: str\n",
    "    recommended_actions: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6374d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Core components implementation\n",
    "class MarketDataProvider:\n",
    "    \"\"\"Unified market data provider with yfinance primary, Alpha Vantage backup\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.alpha_vantage_ts = TimeSeries(key=ALPHA_VANTAGE_API_KEY) if ALPHA_VANTAGE_API_KEY else None\n",
    "        self.alpha_vantage_fd = FundamentalData(key=ALPHA_VANTAGE_API_KEY) if ALPHA_VANTAGE_API_KEY else None\n",
    "        self.rate_limit_delay = 12  # Alpha Vantage rate limit\n",
    "        \n",
    "    async def get_stock_data(self, ticker: str, period: str = \"1y\") -> pd.DataFrame:\n",
    "        \"\"\"Get stock data with yfinance first, Alpha Vantage as backup\"\"\"\n",
    "        try:\n",
    "            # Primary: yfinance\n",
    "            stock = yf.Ticker(ticker)\n",
    "            data = stock.history(period=period)\n",
    "            \n",
    "            if not data.empty:\n",
    "                logger.info(f\"Retrieved {ticker} data from yfinance\")\n",
    "                return self._standardize_data(data, ticker)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"yfinance failed for {ticker}: {e}\")\n",
    "            \n",
    "        # Backup: Alpha Vantage\n",
    "        return await self._get_alpha_vantage_data(ticker)\n",
    "    \n",
    "    async def _get_alpha_vantage_data(self, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Fallback to Alpha Vantage API\"\"\"\n",
    "        if not self.alpha_vantage_ts:\n",
    "            logger.error(\"Alpha Vantage not configured\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        try:\n",
    "            await asyncio.sleep(self.rate_limit_delay)  # Rate limiting\n",
    "            data, _ = self.alpha_vantage_ts.get_daily(symbol=ticker, outputsize='full')\n",
    "            \n",
    "            df = pd.DataFrame(data).T\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df = df.astype(float)\n",
    "            df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "            \n",
    "            logger.info(f\"Retrieved {ticker} data from Alpha Vantage\")\n",
    "            return self._standardize_data(df, ticker)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Alpha Vantage failed for {ticker}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _standardize_data(self, data: pd.DataFrame, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Standardize data format and add technical indicators\"\"\"\n",
    "        if data.empty:\n",
    "            return data\n",
    "            \n",
    "        # Add technical indicators\n",
    "        data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "        data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "        data['RSI'] = self._calculate_rsi(data['Close'])\n",
    "        data['Volatility'] = data['Close'].pct_change().rolling(window=20).std()\n",
    "        data['Ticker'] = ticker\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:\n",
    "        \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "        delta = prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "class NewsMonitor:\n",
    "    \"\"\"Global news monitoring for market events\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.news_api_key = NEWS_API_KEY\n",
    "        self.base_url = \"https://newsapi.org/v2\"\n",
    "        self.risk_keywords = [\n",
    "            \"recession\", \"inflation\", \"interest rates\", \"fed\", \"central bank\",\n",
    "            \"geopolitical\", \"trade war\", \"sanctions\", \"supply chain\", \"earnings\",\n",
    "            \"merger\", \"acquisition\", \"bankruptcy\", \"regulation\", \"crypto\", \"china\"\n",
    "        ]\n",
    "    \n",
    "    async def scan_financial_news(self) -> List[MarketEvent]:\n",
    "        \"\"\"Scan for relevant financial news events\"\"\"\n",
    "        events = []\n",
    "        \n",
    "        try:\n",
    "            for keyword in self.risk_keywords:\n",
    "                url = f\"{self.base_url}/everything\"\n",
    "                params = {\n",
    "                    \"q\": keyword,\n",
    "                    \"language\": \"en\",\n",
    "                    \"sortBy\": \"publishedAt\",\n",
    "                    \"from\": (datetime.now() - timedelta(hours=24)).isoformat(),\n",
    "                    \"apiKey\": self.news_api_key\n",
    "                }\n",
    "                \n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                for article in data.get(\"articles\", [])[:5]:  # Limit per keyword\n",
    "                    event = self._create_market_event(article, keyword)\n",
    "                    if event:\n",
    "                        events.append(event)\n",
    "                \n",
    "                await asyncio.sleep(0.1)  # Rate limiting\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"News scanning failed: {e}\")\n",
    "            \n",
    "        return events\n",
    "    \n",
    "    def _create_market_event(self, article: Dict, keyword: str) -> Optional[MarketEvent]:\n",
    "        \"\"\"Create market event from news article\"\"\"\n",
    "        try:\n",
    "            # Simple ticker extraction (you could enhance with NLP)\n",
    "            affected_tickers = []\n",
    "            title_content = f\"{article['title']} {article.get('description', '')}\"\n",
    "            \n",
    "            for ticker in TICKERS[:20]:  # Check subset for performance\n",
    "                if ticker.lower() in title_content.lower():\n",
    "                    affected_tickers.append(ticker)\n",
    "            \n",
    "            # Calculate severity score based on keyword and source\n",
    "            severity_score = self._calculate_severity(article, keyword)\n",
    "            \n",
    "            return MarketEvent(\n",
    "                timestamp=datetime.fromisoformat(article[\"publishedAt\"].replace(\"Z\", \"+00:00\")),\n",
    "                event_type=keyword,\n",
    "                description=article[\"title\"],\n",
    "                affected_tickers=affected_tickers,\n",
    "                severity_score=severity_score,\n",
    "                source_url=article[\"url\"]\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create event from article: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _calculate_severity(self, article: Dict, keyword: str) -> float:\n",
    "        \"\"\"Calculate event severity score (0-1)\"\"\"\n",
    "        score = 0.5  # Base score\n",
    "        \n",
    "        # Keyword-based scoring\n",
    "        severity_weights = {\n",
    "            \"recession\": 0.9, \"inflation\": 0.8, \"fed\": 0.7,\n",
    "            \"bankruptcy\": 0.9, \"regulation\": 0.6, \"earnings\": 0.4\n",
    "        }\n",
    "        score *= severity_weights.get(keyword, 0.5)\n",
    "        \n",
    "        # Source reliability (simplified)\n",
    "        reliable_sources = [\"reuters\", \"bloomberg\", \"wsj\", \"ft\"]\n",
    "        if any(source in article.get(\"source\", {}).get(\"name\", \"\").lower() for source in reliable_sources):\n",
    "            score *= 1.2\n",
    "        \n",
    "        return min(score, 1.0)\n",
    "\n",
    "class TransformerPredictor(nn.Module):\n",
    "    \"\"\"PyTorch Transformer model for market prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int = 64, hidden_size: int = 256, num_layers: int = 4):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_size, hidden_size)\n",
    "        self.position_encoding = nn.Parameter(torch.randn(1000, hidden_size))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=8,\n",
    "            dim_feedforward=hidden_size * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.output_projection = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project input and add position encoding\n",
    "        x = self.input_projection(x)\n",
    "        x = x + self.position_encoding[:seq_len].unsqueeze(0)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Output projection (predict next day return)\n",
    "        return self.output_projection(x[:, -1, :])\n",
    "\n",
    "class MarketSimulator:\n",
    "    \"\"\"Market simulation and prediction engine\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = TransformerPredictor()\n",
    "        self.scaler = None\n",
    "        self.feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_20', 'SMA_50', 'RSI', 'Volatility']\n",
    "    \n",
    "    def prepare_features(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Prepare features for model input\"\"\"\n",
    "        features = data[self.feature_columns].fillna(method='ffill').fillna(0)\n",
    "        \n",
    "        # Calculate returns and additional features\n",
    "        features['Return'] = data['Close'].pct_change()\n",
    "        features['Volume_MA'] = data['Volume'].rolling(window=20).mean()\n",
    "        features['Price_MA_Ratio'] = data['Close'] / data['SMA_20']\n",
    "        \n",
    "        return features.fillna(0).values\n",
    "    \n",
    "    async def simulate_scenario(self, ticker_data: Dict[str, pd.DataFrame], \n",
    "                               risk_events: List[MarketEvent]) -> Dict[str, Any]:\n",
    "        \"\"\"Simulate market scenarios under risk conditions\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            for ticker, data in ticker_data.items():\n",
    "                if data.empty:\n",
    "                    continue\n",
    "                    \n",
    "                # Prepare features\n",
    "                features = self.prepare_features(data)\n",
    "                \n",
    "                if len(features) < 60:  # Need sufficient history\n",
    "                    continue\n",
    "                \n",
    "                # Create sequences for transformer\n",
    "                sequences = self._create_sequences(features[-60:])  # Last 60 days\n",
    "                \n",
    "                # Simulate baseline scenario\n",
    "                baseline_pred = self._predict_price_series(sequences)\n",
    "                \n",
    "                # Simulate risk-adjusted scenarios\n",
    "                risk_adjusted_preds = []\n",
    "                for event in risk_events:\n",
    "                    if ticker in event.affected_tickers or not event.affected_tickers:\n",
    "                        risk_pred = self._apply_risk_adjustment(baseline_pred, event)\n",
    "                        risk_adjusted_preds.append(risk_pred)\n",
    "                \n",
    "                results[ticker] = {\n",
    "                    \"baseline_prediction\": baseline_pred.tolist(),\n",
    "                    \"risk_scenarios\": risk_adjusted_preds,\n",
    "                    \"current_price\": float(data['Close'].iloc[-1]),\n",
    "                    \"volatility\": float(data['Volatility'].iloc[-1])\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Simulation failed: {e}\")\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def _create_sequences(self, features: np.ndarray, seq_length: int = 30) -> torch.Tensor:\n",
    "        \"\"\"Create sequences for transformer input\"\"\"\n",
    "        sequences = []\n",
    "        for i in range(len(features) - seq_length + 1):\n",
    "            sequences.append(features[i:i + seq_length])\n",
    "        return torch.FloatTensor(sequences)\n",
    "    \n",
    "    def _predict_price_series(self, sequences: torch.Tensor, \n",
    "                             forecast_days: int = 30) -> np.ndarray:\n",
    "        \"\"\"Predict future price series\"\"\"\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_seq = sequences[-1:]  # Last sequence\n",
    "            \n",
    "            for _ in range(forecast_days):\n",
    "                pred = self.model(current_seq)\n",
    "                predictions.append(pred.item())\n",
    "                \n",
    "                # Update sequence (simplified - in practice, you'd update all features)\n",
    "                new_step = current_seq[:, -1:, :].clone()\n",
    "                new_step[:, :, 0] = pred  # Update price feature\n",
    "                current_seq = torch.cat([current_seq[:, 1:, :], new_step], dim=1)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def _apply_risk_adjustment(self, baseline_pred: np.ndarray, \n",
    "                              event: MarketEvent) -> List[float]:\n",
    "        \"\"\"Apply risk event adjustments to baseline predictions\"\"\"\n",
    "        # Risk adjustment factors based on event severity and type\n",
    "        adjustment_factors = {\n",
    "            \"recession\": -0.15, \"inflation\": -0.08, \"earnings\": 0.05,\n",
    "            \"regulation\": -0.12, \"fed\": -0.10, \"geopolitical\": -0.18\n",
    "        }\n",
    "        \n",
    "        factor = adjustment_factors.get(event.event_type, 0.0)\n",
    "        risk_multiplier = factor * event.severity_score\n",
    "        \n",
    "        # Apply time-decaying impact\n",
    "        decay_rates = np.exp(-np.arange(len(baseline_pred)) * 0.1)\n",
    "        adjustments = risk_multiplier * decay_rates\n",
    "        \n",
    "        return (baseline_pred * (1 + adjustments)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4dc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: CrewAI Tools and Agents\n",
    "class MarketDataTool(BaseTool):\n",
    "    name: str = \"market_data_fetcher\"\n",
    "    description: str = \"Fetch real-time market data for specified tickers\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.provider = MarketDataProvider()\n",
    "    \n",
    "    def _run(self, tickers: str) -> str:\n",
    "        \"\"\"Fetch market data for given tickers\"\"\"\n",
    "        ticker_list = [t.strip() for t in tickers.split(\",\")]\n",
    "        results = {}\n",
    "        \n",
    "        loop = asyncio.get_event_loop()\n",
    "        for ticker in ticker_list[:5]:  # Limit for performance\n",
    "            data = loop.run_until_complete(self.provider.get_stock_data(ticker))\n",
    "            if not data.empty:\n",
    "                latest = data.iloc[-1]\n",
    "                results[ticker] = {\n",
    "                    \"price\": float(latest['Close']),\n",
    "                    \"volume\": float(latest['Volume']),\n",
    "                    \"volatility\": float(latest['Volatility']),\n",
    "                    \"rsi\": float(latest['RSI'])\n",
    "                }\n",
    "        \n",
    "        return json.dumps(results)\n",
    "\n",
    "class NewsAnalysisTool(BaseTool):\n",
    "    name: str = \"news_analyzer\"\n",
    "    description: str = \"Analyze recent financial news for market risks\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.monitor = NewsMonitor()\n",
    "    \n",
    "    def _run(self, query: str = \"\") -> str:\n",
    "        \"\"\"Scan and analyze recent financial news\"\"\"\n",
    "        loop = asyncio.get_event_loop()\n",
    "        events = loop.run_until_complete(self.monitor.scan_financial_news())\n",
    "        \n",
    "        event_summaries = []\n",
    "        for event in events[:10]:  # Top 10 events\n",
    "            event_summaries.append({\n",
    "                \"timestamp\": event.timestamp.isoformat(),\n",
    "                \"type\": event.event_type,\n",
    "                \"description\": event.description,\n",
    "                \"severity\": event.severity_score,\n",
    "                \"affected_tickers\": event.affected_tickers\n",
    "            })\n",
    "        \n",
    "        return json.dumps(event_summaries)\n",
    "\n",
    "class SimulationTool(BaseTool):\n",
    "    name: str = \"market_simulator\"\n",
    "    description: str = \"Run market simulations under different risk scenarios\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.simulator = MarketSimulator()\n",
    "        self.provider = MarketDataProvider()\n",
    "    \n",
    "    def _run(self, tickers_and_events: str) -> str:\n",
    "        \"\"\"Run market simulations\"\"\"\n",
    "        try:\n",
    "            data = json.loads(tickers_and_events)\n",
    "            tickers = data.get(\"tickers\", [])\n",
    "            events_data = data.get(\"events\", [])\n",
    "            \n",
    "            # Convert events data back to MarketEvent objects\n",
    "            events = []\n",
    "            for event_data in events_data:\n",
    "                events.append(MarketEvent(\n",
    "                    timestamp=datetime.fromisoformat(event_data[\"timestamp\"]),\n",
    "                    event_type=event_data[\"type\"],\n",
    "                    description=event_data[\"description\"],\n",
    "                    affected_tickers=event_data[\"affected_tickers\"],\n",
    "                    severity_score=event_data[\"severity\"],\n",
    "                    source_url=\"\"\n",
    "                ))\n",
    "            \n",
    "            # Get market data\n",
    "            loop = asyncio.get_event_loop()\n",
    "            ticker_data = {}\n",
    "            for ticker in tickers[:5]:  # Limit for performance\n",
    "                data = loop.run_until_complete(self.provider.get_stock_data(ticker))\n",
    "                if not data.empty:\n",
    "                    ticker_data[ticker] = data\n",
    "            \n",
    "            # Run simulations\n",
    "            results = loop.run_until_complete(\n",
    "                self.simulator.simulate_scenario(ticker_data, events)\n",
    "            )\n",
    "            \n",
    "            return json.dumps(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Simulation failed: {str(e)}\"\n",
    "\n",
    "# CrewAI Agents\n",
    "def create_horizon_scanner_agent():\n",
    "    \"\"\"Create the Horizon Scanner Agent\"\"\"\n",
    "    return Agent(\n",
    "        role=\"Market Horizon Scanner\",\n",
    "        goal=\"Continuously monitor global markets and news for emerging risk signals\",\n",
    "        backstory=\"\"\"You are an expert market surveillance analyst with deep experience \n",
    "        in identifying early warning signals across global financial markets. You excel \n",
    "        at connecting seemingly unrelated events to potential market impacts.\"\"\",\n",
    "        tools=[MarketDataTool(), NewsAnalysisTool()],\n",
    "        verbose=True,\n",
    "        allow_delegation=False\n",
    "    )\n",
    "\n",
    "def create_economic_analyst_agent():\n",
    "    \"\"\"Create the Economic Analyst Agent\"\"\"\n",
    "    return Agent(\n",
    "        role=\"Senior Economic Analyst\",\n",
    "        goal=\"Analyze market events and assess their potential economic impact\",\n",
    "        backstory=\"\"\"You are a senior economist with 15+ years of experience analyzing \n",
    "        market events and their cascading effects across different sectors and geographies. \n",
    "        You specialize in second-order effect analysis and risk quantification.\"\"\",\n",
    "        tools=[],\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        llm_config={\n",
    "            \"model\": \"gemini-pro\",\n",
    "            \"api_key\": GEMINI_API_KEY\n",
    "        } if GEMINI_API_KEY else None\n",
    "    )\n",
    "\n",
    "def create_simulation_agent():\n",
    "    \"\"\"Create the Simulation Agent\"\"\"\n",
    "    return Agent(\n",
    "        role=\"Quantitative Risk Modeler\",\n",
    "        goal=\"Run predictive simulations and model potential market scenarios\",\n",
    "        backstory=\"\"\"You are a quantitative analyst specializing in market risk modeling \n",
    "        and scenario analysis. You use advanced mathematical models to predict market \n",
    "        behavior under different risk conditions.\"\"\",\n",
    "        tools=[SimulationTool()],\n",
    "        verbose=True,\n",
    "        allow_delegation=False\n",
    "    )\n",
    "\n",
    "def create_briefing_agent():\n",
    "    \"\"\"Create the Briefing Agent\"\"\"\n",
    "    return Agent(\n",
    "        role=\"Risk Intelligence Briefer\",\n",
    "        goal=\"Synthesize analysis into actionable client briefings\",\n",
    "        backstory=\"\"\"You are a senior risk communication specialist who translates \n",
    "        complex market analysis into clear, actionable intelligence for institutional \n",
    "        clients. You excel at prioritizing risks and recommending specific actions.\"\"\",\n",
    "        tools=[],\n",
    "        verbose=True,\n",
    "        allow_delegation=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132f83f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 184\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Option 2: Continuous monitoring (uncomment to enable)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# monitor = ContinuousMonitor(pipeline)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m#     monitor.stop_monitoring()\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m#     logger.info(\"Pipeline stopped by user\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Fitch Market Risk Pipeline implementation complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo use this pipeline:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fin-ai1/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Cell 4: Pipeline orchestration and main execution\n",
    "class MarketRiskPipeline:\n",
    "    \"\"\"Main pipeline orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents = {\n",
    "            \"scanner\": create_horizon_scanner_agent(),\n",
    "            \"analyst\": create_economic_analyst_agent(),\n",
    "            \"simulator\": create_simulation_agent(),\n",
    "            \"briefer\": create_briefing_agent()\n",
    "        }\n",
    "        \n",
    "        self.sendgrid_client = sendgrid.SendGridAPIClient(api_key=SENDGRID_API_KEY) if SENDGRID_API_KEY else None\n",
    "    \n",
    "    async def run_pipeline(self) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the complete risk analysis pipeline\"\"\"\n",
    "        logger.info(\"Starting Predictive Market Risk Pipeline\")\n",
    "        \n",
    "        # Task 1: Horizon Scanning\n",
    "        scanning_task = Task(\n",
    "            description=f\"\"\"Scan global markets and news for emerging risks affecting these tickers: \n",
    "            {', '.join(TICKERS[:20])}. Focus on events from the last 24 hours that could impact \n",
    "            market sentiment or specific sectors. Provide market data and news analysis.\"\"\",\n",
    "            agent=self.agents[\"scanner\"],\n",
    "            expected_output=\"JSON formatted market data and news events with risk indicators\"\n",
    "        )\n",
    "        \n",
    "        # Task 2: Economic Analysis\n",
    "        analysis_task = Task(\n",
    "            description=\"\"\"Analyze the market events identified by the scanner. Assess the potential \n",
    "            economic impact, identify second-order effects, and quantify risk probabilities. \n",
    "            Consider sector correlations and macroeconomic implications.\"\"\",\n",
    "            agent=self.agents[\"analyst\"],\n",
    "            expected_output=\"Detailed risk assessment with impact analysis and probability scores\"\n",
    "        )\n",
    "        \n",
    "        # Task 3: Market Simulation\n",
    "        simulation_task = Task(\n",
    "            description=\"\"\"Run predictive simulations based on the identified risks and market data. \n",
    "            Model different scenarios showing potential price impacts over 1-week, 1-month, and \n",
    "            3-month horizons. Include confidence intervals and risk-adjusted predictions.\"\"\",\n",
    "            agent=self.agents[\"simulator\"],\n",
    "            expected_output=\"Simulation results with predicted price paths and scenario analysis\"\n",
    "        )\n",
    "        \n",
    "        # Task 4: Client Briefing\n",
    "        briefing_task = Task(\n",
    "            description=\"\"\"Synthesize all analysis into a comprehensive risk briefing for Fitch \n",
    "            clients. Prioritize the most critical risks, provide clear impact assessments, and \n",
    "            recommend specific portfolio actions. Format for executive consumption.\"\"\",\n",
    "            agent=self.agents[\"briefer\"],\n",
    "            expected_output=\"Executive risk briefing with prioritized risks and action items\"\n",
    "        )\n",
    "        \n",
    "        # Create and execute crew\n",
    "        crew = Crew(\n",
    "            agents=list(self.agents.values()),\n",
    "            tasks=[scanning_task, analysis_task, simulation_task, briefing_task],\n",
    "            process=Process.sequential,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            result = crew.kickoff()\n",
    "            \n",
    "            # Store results in Supabase\n",
    "            if supabase:\n",
    "                await self._store_results(result)\n",
    "            \n",
    "            # Send briefing to clients\n",
    "            if self.sendgrid_client:\n",
    "                await self._send_briefing(result.raw)\n",
    "            \n",
    "            logger.info(\"Pipeline execution completed successfully\")\n",
    "            return {\"status\": \"success\", \"results\": result.raw}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline execution failed: {e}\")\n",
    "            return {\"status\": \"error\", \"error\": str(e)}\n",
    "    \n",
    "    async def _store_results(self, results: Any):\n",
    "        \"\"\"Store pipeline results in Supabase\"\"\"\n",
    "        try:\n",
    "            data = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"pipeline_results\": str(results),\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "            \n",
    "            supabase.table(\"risk_pipeline_runs\").insert(data).execute()\n",
    "            logger.info(\"Results stored in Supabase\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to store results: {e}\")\n",
    "    \n",
    "    async def _send_briefing(self, briefing_content: str):\n",
    "        \"\"\"Send risk briefing via SendGrid\"\"\"\n",
    "        try:\n",
    "            message = Mail(\n",
    "                from_email='risk-pipeline@fitch.com',\n",
    "                to_emails='clients@fitch.com',\n",
    "                subject=f'Market Risk Briefing - {datetime.now().strftime(\"%Y-%m-%d\")}',\n",
    "                html_content=f\"\"\"\n",
    "                <h2>Fitch Market Risk Intelligence</h2>\n",
    "                <p><strong>Generated:</strong> {datetime.now().strftime(\"%Y-%m-%d %H:%M UTC\")}</p>\n",
    "                <div style=\"white-space: pre-wrap; font-family: monospace;\">\n",
    "                {briefing_content}\n",
    "                </div>\n",
    "                <hr>\n",
    "                <p><em>This briefing was generated by Fitch's Predictive Market Risk Pipeline</em></p>\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "            response = self.sendgrid_client.send(message)\n",
    "            logger.info(f\"Briefing sent successfully: {response.status_code}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to send briefing: {e}\")\n",
    "\n",
    "# Background worker for continuous monitoring\n",
    "class ContinuousMonitor:\n",
    "    \"\"\"Background worker for 24/7 market monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline: MarketRiskPipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.running = False\n",
    "        self.check_interval = 3600  # 1 hour\n",
    "    \n",
    "    async def start_monitoring(self):\n",
    "        \"\"\"Start continuous monitoring loop\"\"\"\n",
    "        self.running = True\n",
    "        logger.info(\"Starting continuous market monitoring\")\n",
    "        \n",
    "        while self.running:\n",
    "            try:\n",
    "                # Check if markets are open (simplified)\n",
    "                current_hour = datetime.now().hour\n",
    "                if 9 <= current_hour <= 16:  # Market hours (EST)\n",
    "                    await self.pipeline.run_pipeline()\n",
    "                else:\n",
    "                    logger.info(\"Markets closed, monitoring news only\")\n",
    "                    # Run reduced scan for major news events\n",
    "                    \n",
    "                await asyncio.sleep(self.check_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Monitoring error: {e}\")\n",
    "                await asyncio.sleep(300)  # 5 minute error recovery\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"Stop the monitoring loop\"\"\"\n",
    "        self.running = False\n",
    "        logger.info(\"Stopping continuous monitoring\")\n",
    "\n",
    "# Main execution\n",
    "async def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Verify environment setup\n",
    "    required_env_vars = [\"ALPHA_VANTAGE_API_KEY\", \"NEWS_API_KEY\", \"GEMINI_API_KEY\"]\n",
    "    missing_vars = [var for var in required_env_vars if not os.getenv(var)]\n",
    "    \n",
    "    if missing_vars:\n",
    "        logger.warning(f\"Missing environment variables: {missing_vars}\")\n",
    "        logger.warning(\"Some features may be limited\")\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = MarketRiskPipeline()\n",
    "    \n",
    "    # Option 1: Run once\n",
    "    print(\"Running Fitch Predictive Market Risk Pipeline...\")\n",
    "    results = await pipeline.run_pipeline()\n",
    "    print(f\"Pipeline completed with status: {results['status']}\")\n",
    "    \n",
    "    # Option 2: Continuous monitoring (uncomment to enable)\n",
    "    # monitor = ContinuousMonitor(pipeline)\n",
    "    # try:\n",
    "    #     await monitor.start_monitoring()\n",
    "    # except KeyboardInterrupt:\n",
    "    #     monitor.stop_monitoring()\n",
    "    #     logger.info(\"Pipeline stopped by user\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "\n",
    "print(\"✅ Fitch Market Risk Pipeline implementation complete!\")\n",
    "print(\"\\nTo use this pipeline:\")\n",
    "print(\"1. Set required environment variables\")\n",
    "print(\"2. Run each cell sequentially\")\n",
    "print(\"3. The pipeline will execute and provide risk analysis results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1201d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
